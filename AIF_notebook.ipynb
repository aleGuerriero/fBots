{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPWaUpmQ5/MdyHEr36DuXc/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleGuerriero/fBots/blob/main/AIF_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pokémon VGC AI Competition\n",
        "\n",
        "## Course  \n",
        "- **Artificial Intelligence Fundamentals**  \n",
        "\n",
        "## Authors  \n",
        "- **Alessandro Guerriero**  \n",
        "- **Riccardo Berni**  \n",
        "- **Elia Boccini**  \n",
        "\n",
        "## Year  \n",
        "- **2024/2025**  \n",
        "\n",
        "\\\\\n",
        "\n",
        "\n",
        "\n",
        "## Introduction  \n",
        "In this report, we will examine our project related to the **Pokémon VGC AI competition**. It explores the intersection of artificial intelligence and competitive Pokémon battles.\n",
        "\n",
        "The goal of our work is to develop an AI system capable of tackling challenges in the Pokémon VGC (Video Game Championships) competition, using algorithms and techniques learned during the course of *Artificial Intelligence Fundamentals*.  \n",
        "\n",
        "This report outlines the methodologies, results, and key insights from our project, focusing on both the development process and performance evaluation."
      ],
      "metadata": {
        "id": "8YADoMP-Jn1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pokémon VGC Engine\n",
        "The pokémon VGC Engine is a new model of Meta-Game Balance AI Competition. It is composed of two main tracks:\n",
        "-  Battle Track\n",
        "  - Simulatesturn-based battles following VGC rules\n",
        "  - The player agent competes against opponents\n",
        "  - Three matches for round\n",
        "## Enviroment\n",
        "\n",
        "\n",
        "## Objectives  \n",
        "- Create an AI system capable of simulating and competing in Pokémon VGC battles.  \n",
        "- Apply machine learning algorithms and strategic research to improve the system’s performance.  \n",
        "- Analyze the results and compare them with previous approaches.  \n",
        "\n",
        "## Related Works  \n",
        "In Pokémon VGC AI, several approaches based on neural networks, genetic algorithms, and reinforcement learning models exist. Recent studies have demonstrated that using convolutional neural networks (CNN) and deep reinforcement learning methods can significantly improve performance in complex strategic games like Pokémon VGC.  \n",
        "\n",
        "## Methodologies  \n",
        "The main methodologies used in our project include:  \n",
        "- **Reinforcement Learning (RL)**: Implemented using RL models to learn optimal battle strategies.  \n",
        "- **Convolutional Neural Networks (CNN)**: Used to analyze battle data and identify effective patterns.  \n",
        "- **Simulations**: Using simulation environments to train the AI system and evaluate its performance.  \n",
        "\n",
        "### Example Code (in Google Colab)  \n",
        "An example of code used to train an RL model could be:  \n",
        "\n",
        "```python  \n",
        "import gym  \n",
        "import numpy as np  \n",
        "from stable_baselines3 import PPO  \n",
        "\n",
        "# Create simulation environment  \n",
        "env = gym.make('PokemonVGCEnv-v0')  \n",
        "\n",
        "# RL model with PPO  \n",
        "model = PPO('MlpPolicy', env, verbose=1)  \n",
        "model.learn(total_timesteps=100000)  \n",
        "\n",
        "# Run the trained model on simulated battles  \n",
        "obs = env.reset()  \n",
        "done = False  \n",
        "while not done:  \n",
        "    action, _ = model.predict(obs)  \n",
        "    obs, reward, done, _ = env.step(action)  "
      ],
      "metadata": {
        "id": "PbhY8PEmQFTC"
      }
    }
  ]
}